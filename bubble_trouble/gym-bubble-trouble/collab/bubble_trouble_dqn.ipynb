{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bubble_trouble_dqn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"--4Tvqn6sI0B","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run this only once whenever the notebook is opened.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K1R_H3a1tEoS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":301},"outputId":"7ed5ebb3-cf8c-4487-b7b0-521727658d96","executionInfo":{"status":"ok","timestamp":1555284130994,"user_tz":240,"elapsed":7666,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}}},"cell_type":"code","source":["!cd drive/My\\ Drive/gym-bubble-trouble && pip install -e . && cd gym_bubbletrouble/envs/\n","!pip install pygame\n","%cd drive/My\\ Drive/gym-bubble-trouble/gym_bubbletrouble/envs/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Obtaining file:///content/drive/My%20Drive/gym-bubble-trouble\n","Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from gym-bubbletrouble==0.0.1) (0.10.11)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (1.2.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (1.16.2)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (1.11.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (1.3.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym->gym-bubbletrouble==0.0.1) (0.16.0)\n","Installing collected packages: gym-bubbletrouble\n","  Found existing installation: gym-bubbletrouble 0.0.1\n","    Can't uninstall 'gym-bubbletrouble'. No files were found to uninstall.\n","  Running setup.py develop for gym-bubbletrouble\n","Successfully installed gym-bubbletrouble\n","Requirement already satisfied: pygame in /usr/local/lib/python3.6/dist-packages (1.9.5)\n","/content/drive/My Drive/gym-bubble-trouble/gym_bubbletrouble/envs\n"],"name":"stdout"}]},{"metadata":{"id":"o_NDY8EPyjGR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"c333f219-6048-42fd-c702-a54e943741b6","executionInfo":{"status":"ok","timestamp":1555284131688,"user_tz":240,"elapsed":7069,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}}},"cell_type":"code","source":["from bubbletrouble_env import BubbleTroubleEnv\n","import gym\n","import math\n","import random\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","from PIL import Image\n","import numpy as np\n","\n","from IPython.display import clear_output\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","import gym.spaces\n","\n","env = BubbleTroubleEnv(rand=True)\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["pygame 1.9.5\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n"],"name":"stdout"}]},{"metadata":{"id":"I8mE9PGG0r--","colab_type":"code","colab":{}},"cell_type":"code","source":["class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        \"\"\"Saves a transition.\"\"\"\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","\n","\n","class DQN(nn.Module):\n","    def __init__(self, h, w, outputs):\n","        super(DQN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n","        self.bn3 = nn.BatchNorm2d(32)\n","\n","        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n","            return (size - (kernel_size - 1) - 1) // stride  + 1\n","\n","        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n","        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n","        linear_input_size = convw * convh * 32\n","        self.head = nn.Linear(linear_input_size, outputs)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        return self.head(x.view(x.size(0), -1))\n","\n","\n","resize = T.Compose([T.ToPILImage(),\n","                    T.Resize(80, interpolation=Image.CUBIC),\n","                    T.ToTensor()])\n","\n","\n","def get_screen():\n","    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n","    return resize(screen).unsqueeze(0).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fAwvCd1H0z20","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"outputId":"51faa11e-feeb-472b-e390-22ffa16dbdd3","executionInfo":{"status":"ok","timestamp":1555284134498,"user_tz":240,"elapsed":4372,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}}},"cell_type":"code","source":["env.reset()\n","plt.figure()\n","plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n","           interpolation='none')\n","plt.title('Example extracted screen')\n","plt.show()"],"execution_count":4,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUUAAAEICAYAAADIsubvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"oj1BzUyV1Moe","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 128\n","GAMMA = 0.999\n","EPS_START = 0.9\n","EPS_END = 0.05\n","EPS_DECAY = 200\n","TARGET_UPDATE = 10\n","\n","# Get screen size so that we can initialize layers correctly based on shape\n","# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n","# which is the result of a clamped and down-scaled render buffer in get_screen()\n","init_screen = get_screen()\n","_, _, screen_height, screen_width = init_screen.shape\n","\n","# Get number of actions from gym action space\n","n_actions = env.action_space.n\n","\n","policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","target_net.eval()\n","\n","optimizer = optim.RMSprop(policy_net.parameters())\n","memory = ReplayMemory(10000)\n","\n","\n","steps_done = 0\n","\n","\n","def select_action(state, model=policy_net):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","    steps_done += 1\n","    if sample > eps_threshold:\n","        with torch.no_grad():\n","            # t.max(1) will return largest column value of each row.\n","            # second column on max result is index of where max element was\n","            # found, so we pick action with the larger expected reward.\n","            return model(state).max(1)[1].view(1, 1)\n","    else:\n","        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n","\n","\n","episode_durations = []"],"execution_count":0,"outputs":[]},{"metadata":{"id":"na85-hid0-9I","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_durations():\n","    plt.figure(2)\n","    plt.clf()\n","    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n","    plt.title('Training...')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Duration')\n","    plt.plot(durations_t.numpy())\n","    # Take 100 episode averages and plot them too\n","    if len(durations_t) >= 100:\n","        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n","        means = torch.cat((torch.zeros(99), means))\n","        plt.plot(means.numpy())\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","def optimize_model():\n","    if len(memory) < BATCH_SIZE:\n","        return\n","    transitions = memory.sample(BATCH_SIZE)\n","    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n","    # detailed explanation). This converts batch-array of Transitions\n","    # to Transition of batch-arrays.\n","    batch = Transition(*zip(*transitions))\n","\n","    # Compute a mask of non-final states and concatenate the batch elements\n","    # (a final state would've been the one after which simulation ended)\n","    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)), device=device, dtype=torch.uint8)\n","    non_final_next_states = torch.cat([s for s in batch.next_state\n","                                                if s is not None])\n","    state_batch = torch.cat(batch.state)\n","    action_batch = torch.cat(batch.action)\n","    reward_batch = torch.cat(batch.reward)\n","\n","    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","    # columns of actions taken. These are the actions which would've been taken\n","    # for each batch state according to policy_net\n","    state_action_values = policy_net(state_batch).gather(1, action_batch)\n","\n","    # Compute V(s_{t+1}) for all next states.\n","    # Expected values of actions for non_final_next_states are computed based\n","    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n","    # This is merged based on the mask, such that we'll have either the expected\n","    # state value or 0 in case the state was final.\n","    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n","    # Compute the expected Q values\n","    expected_state_action_values = (next_state_values * GAMMA) + reward_batch.type(torch.float)\n","\n","    # Compute Huber loss\n","    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n","\n","    # Optimize the model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    for param in policy_net.parameters():\n","        param.grad.data.clamp_(-1, 1)\n","    optimizer.step()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"avIvT6WS1EZ2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"4edd695c-5043-48d1-c1e0-31f343ec6a15"},"cell_type":"code","source":["import copy\n","\n","T_LIMIT = 25 * 30 * 2\n","num_episodes = 200\n","best_model = None\n","best_fitness = -10000\n","min_delta = 100\n","\n","for i_episode in range(num_episodes):\n","    # Initialize the environment and state\n","    env.reset()\n","    last_screen = get_screen()\n","    current_screen = get_screen()\n","    state = current_screen - last_screen\n","    for t in count():\n","        # Select and perform an action\n","        action = select_action(state)\n","        \n","        _, r, done, _ = env.step(action.item())\n","        reward = torch.tensor([r], device=device)\n","        \n","        if t > T_LIMIT:\n","            r += -10000\n","            done = True\n","\n","        # Observe new state\n","        last_screen = current_screen\n","        current_screen = get_screen()\n","          \n","        if not done:\n","            next_state = current_screen - last_screen\n","        else:\n","            next_state = None\n","\n","        # Store the transition in memory\n","        memory.push(state, action, next_state, reward)\n","\n","        # Move to the next state\n","        state = next_state\n","\n","        # Perform one step of the optimization (on the target network)\n","        optimize_model()\n","        \n","        if done:\n","            episode_durations.append(t + 1)\n","            clear_output(wait=False)\n","            print('Episode {}: reward={} with {} steps'\n","                  .format(i_episode, r, t + 1))\n","            if r > best_fitness + min_delta:\n","              best_fitness = r\n","              best_model = copy.deepcopy(policy_net)\n","            break\n","            \n","    # Update the target network, copying all weights and biases in DQN\n","    if i_episode % TARGET_UPDATE == 0:\n","        target_net.load_state_dict(policy_net.state_dict())      \n","\n","print('Complete')\n","plot_durations()\n","env.render()\n","plt.ioff()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Episode 15: reward=-9455 with 259 steps\n"],"name":"stdout"}]},{"metadata":{"id":"eFNycXmvep5w","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"751dfa6d-3703-4c6f-f80c-c966daca3b17","executionInfo":{"status":"ok","timestamp":1555283560882,"user_tz":240,"elapsed":344,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}}},"cell_type":"code","source":["torch.save(policy_net, 'best_model')"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/serialization.py:251: UserWarning: Couldn't retrieve source code for container of type DQN. It won't be checked for correctness upon loading.\n","  \"type \" + obj.__name__ + \". It won't be checked \"\n"],"name":"stderr"}]},{"metadata":{"id":"jCg8D13Qy_I8","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":732},"outputId":"ccfa68ee-dd1c-4188-95f9-c9b5f48edec2","executionInfo":{"status":"error","timestamp":1555283758359,"user_tz":240,"elapsed":384,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}}},"cell_type":"code","source":["# Testing the policy\n","from gym import wrappers\n","\n","best_model = torch.load('best_model')\n","env.reset()\n","\n","last_screen = get_screen()\n","current_screen = get_screen()\n","state = current_screen - last_screen\n","\n","img_array = []\n","\n","for i in range(1000):\n","    img_array.append(current_screen.cpu().squeeze(0).permute(1, 2, 0).numpy())\n","    action = select_action(state, model=best_model)\n","    _, _, done, _ = env.step(action.item())\n","    \n","    last_screen = current_screen\n","    current_screen = get_screen()\n","\n","    state = current_screen - last_screen\n","    if done:\n","      break\n","      \n","# env.close()"],"execution_count":18,"outputs":[{"output_type":"error","ename":"error","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-534fda8ce9ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlast_screen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_screen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/gym-bubble-trouble/gym_bubbletrouble/envs/bubbletrouble_env.py\u001b[0m in \u001b[0;36mreset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/gym-bubble-trouble/gym_bubbletrouble/envs/bubbletrouble_env.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_world\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0mbt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/gym-bubble-trouble/gym_bubbletrouble/envs/bt.py\u001b[0m in \u001b[0;36mdraw_world\u001b[0;34m()\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mdraw_player\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0mdraw_player_lives\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0mdraw_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/My Drive/gym-bubble-trouble/gym_bubbletrouble/envs/bt.py\u001b[0m in \u001b[0;36mdraw_timer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_timer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mtimer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_rect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottomleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWINDOWHEIGHT\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31merror\u001b[0m: Text has zero width"]}]},{"metadata":{"id":"QznJ2X6kzxZW","colab_type":"code","colab":{}},"cell_type":"code","source":["import cv2\n","import glob\n"," \n","out = cv2.VideoWriter(\n","    'dqn-result.mp4',\n","    cv2.VideoWriter_fourcc(*'DIVX'), \n","    30, \n","    (screen_width, screen_height)\n",")\n","for img in img_array:\n","    img_norm = cv2.cvtColor(np.uint8(img * 255), cv2.COLOR_BGR2RGB)\n","    out.write(img_norm)\n","out.release()\n"],"execution_count":0,"outputs":[]}]}