{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bubble_trouble_dqn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"--4Tvqn6sI0B","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run this only once whenever the notebook is opened.\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K1R_H3a1tEoS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":301},"outputId":"ba2f38ea-7124-4920-a444-09dc01cc4807","executionInfo":{"status":"ok","timestamp":1555265679049,"user_tz":240,"elapsed":8050,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}}},"cell_type":"code","source":["!cd drive/My\\ Drive/gym-bubble-trouble && pip install -e . && cd gym_bubbletrouble/envs/\n","!pip install pygame\n","%cd drive/My\\ Drive/gym-bubble-trouble/gym_bubbletrouble/envs/"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Obtaining file:///content/drive/My%20Drive/gym-bubble-trouble\n","Requirement already satisfied: gym in /usr/local/lib/python3.6/dist-packages (from gym-bubbletrouble==0.0.1) (0.10.11)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (1.2.1)\n","Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (1.16.2)\n","Requirement already satisfied: requests>=2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (2.10.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (1.11.0)\n","Requirement already satisfied: pyglet>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from gym->gym-bubbletrouble==0.0.1) (1.3.2)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet>=1.2.0->gym->gym-bubbletrouble==0.0.1) (0.16.0)\n","Installing collected packages: gym-bubbletrouble\n","  Found existing installation: gym-bubbletrouble 0.0.1\n","    Can't uninstall 'gym-bubbletrouble'. No files were found to uninstall.\n","  Running setup.py develop for gym-bubbletrouble\n","Successfully installed gym-bubbletrouble\n","Requirement already satisfied: pygame in /usr/local/lib/python3.6/dist-packages (1.9.5)\n","/content/drive/My Drive/gym-bubble-trouble/gym_bubbletrouble/envs\n"],"name":"stdout"}]},{"metadata":{"id":"o_NDY8EPyjGR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"e9e54cc3-dc54-44ce-c6fc-06bb9ad3515a","executionInfo":{"status":"ok","timestamp":1555265679843,"user_tz":240,"elapsed":7001,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}}},"cell_type":"code","source":["from bubbletrouble_env import BubbleTroubleEnv\n","import gym\n","import math\n","import random\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","from PIL import Image\n","import numpy as np\n","\n","from IPython.display import clear_output\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","import gym.spaces\n","\n","env = BubbleTroubleEnv()\n","\n","# if gpu is to be used\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))"],"execution_count":2,"outputs":[{"output_type":"stream","text":["pygame 1.9.5\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n"],"name":"stdout"}]},{"metadata":{"id":"I8mE9PGG0r--","colab_type":"code","colab":{}},"cell_type":"code","source":["class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        \"\"\"Saves a transition.\"\"\"\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","\n","\n","class DQN(nn.Module):\n","    def __init__(self, h, w, outputs):\n","        super(DQN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n","        self.bn3 = nn.BatchNorm2d(32)\n","\n","        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n","            return (size - (kernel_size - 1) - 1) // stride  + 1\n","\n","        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n","        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n","        linear_input_size = convw * convh * 32\n","        self.head = nn.Linear(linear_input_size, outputs)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        return self.head(x.view(x.size(0), -1))\n","\n","\n","resize = T.Compose([T.ToPILImage(),\n","                    T.Resize(100, interpolation=Image.CUBIC),\n","                    T.ToTensor()])\n","\n","\n","def get_screen():\n","    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n","    return resize(screen).unsqueeze(0).to(device)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"fAwvCd1H0z20","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":281},"outputId":"5da0571e-7761-446b-dd39-ce880b76c4fb","executionInfo":{"status":"ok","timestamp":1555265942006,"user_tz":240,"elapsed":507,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}}},"cell_type":"code","source":["env.reset()\n","plt.figure()\n","plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n","           interpolation='none')\n","plt.title('Example extracted screen')\n","plt.show()"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUYAAAEICAYAAAAjhV3sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"oj1BzUyV1Moe","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 128\n","GAMMA = 0.999\n","EPS_START = 0.9\n","EPS_END = 0.05\n","EPS_DECAY = 200\n","TARGET_UPDATE = 10\n","\n","# Get screen size so that we can initialize layers correctly based on shape\n","# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n","# which is the result of a clamped and down-scaled render buffer in get_screen()\n","init_screen = get_screen()\n","_, _, screen_height, screen_width = init_screen.shape\n","\n","# Get number of actions from gym action space\n","n_actions = env.action_space.n\n","\n","policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net = DQN(screen_height, screen_width, n_actions).to(device)\n","target_net.load_state_dict(policy_net.state_dict())\n","target_net.eval()\n","\n","optimizer = optim.RMSprop(policy_net.parameters())\n","memory = ReplayMemory(10000)\n","\n","\n","steps_done = 0\n","\n","\n","def select_action(state):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","    steps_done += 1\n","    if sample > eps_threshold:\n","        with torch.no_grad():\n","            # t.max(1) will return largest column value of each row.\n","            # second column on max result is index of where max element was\n","            # found, so we pick action with the larger expected reward.\n","            return policy_net(state).max(1)[1].view(1, 1)\n","    else:\n","        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n","\n","\n","episode_durations = []"],"execution_count":0,"outputs":[]},{"metadata":{"id":"na85-hid0-9I","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","\n","def plot_durations():\n","    plt.figure(2)\n","    plt.clf()\n","    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n","    plt.title('Training...')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Duration')\n","    plt.plot(durations_t.numpy())\n","    # Take 100 episode averages and plot them too\n","    if len(durations_t) >= 100:\n","        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n","        means = torch.cat((torch.zeros(99), means))\n","        plt.plot(means.numpy())\n","    plt.pause(0.001)  # pause a bit so that plots are updated\n","\n","\n","def optimize_model():\n","    if len(memory) < BATCH_SIZE:\n","        return\n","    transitions = memory.sample(BATCH_SIZE)\n","    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n","    # detailed explanation). This converts batch-array of Transitions\n","    # to Transition of batch-arrays.\n","    batch = Transition(*zip(*transitions))\n","\n","    # Compute a mask of non-final states and concatenate the batch elements\n","    # (a final state would've been the one after which simulation ended)\n","    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)), device=device, dtype=torch.uint8)\n","    non_final_next_states = torch.cat([s for s in batch.next_state\n","                                                if s is not None])\n","    state_batch = torch.cat(batch.state)\n","    action_batch = torch.cat(batch.action)\n","    reward_batch = torch.cat(batch.reward)\n","\n","    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n","    # columns of actions taken. These are the actions which would've been taken\n","    # for each batch state according to policy_net\n","    state_action_values = policy_net(state_batch).gather(1, action_batch)\n","\n","    # Compute V(s_{t+1}) for all next states.\n","    # Expected values of actions for non_final_next_states are computed based\n","    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n","    # This is merged based on the mask, such that we'll have either the expected\n","    # state value or 0 in case the state was final.\n","    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n","    # Compute the expected Q values\n","    expected_state_action_values = (next_state_values * GAMMA) + reward_batch.type(torch.float)\n","\n","    # Compute Huber loss\n","    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n","\n","    # Optimize the model\n","    optimizer.zero_grad()\n","    loss.backward()\n","    for param in policy_net.parameters():\n","        param.grad.data.clamp_(-1, 1)\n","    optimizer.step()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"avIvT6WS1EZ2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/"},"outputId":"c6aa0c24-56b9-4932-ad09-270872da01b7"},"cell_type":"code","source":["num_episodes = 1000\n","for i_episode in range(num_episodes):\n","    # Initialize the environment and state\n","    env.reset()\n","    last_screen = get_screen()\n","    current_screen = get_screen()\n","    state = current_screen - last_screen\n","    for t in count():\n","        # Select and perform an action\n","        action = select_action(state)\n","        \n","        _, reward, done, _ = env.step(action.item())\n","        reward = torch.tensor([reward], device=device)\n","\n","        # Observe new state\n","        last_screen = current_screen\n","        current_screen = get_screen()\n","          \n","        if not done:\n","            next_state = current_screen - last_screen\n","        else:\n","            next_state = None\n","\n","        # Store the transition in memory\n","        memory.push(state, action, next_state, reward)\n","\n","        # Move to the next state\n","        state = next_state\n","\n","        # Perform one step of the optimization (on the target network)\n","        optimize_model()\n","        \n","        if done:\n","            episode_durations.append(t + 1)\n","            clear_output(wait=False)\n","            print('Episode {}: reward={}, restart={}'\n","                  .format(i_episode, reward, done))\n","            break\n","            \n","    # Update the target network, copying all weights and biases in DQN\n","    if i_episode % TARGET_UPDATE == 0:\n","        target_net.load_state_dict(policy_net.state_dict())      \n","\n","print('Complete')\n","plot_durations()\n","env.render()\n","env.close()\n","plt.ioff()\n","plt.show()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Episode 144: reward=tensor([-10040], device='cuda:0'), restart=True\n"],"name":"stdout"}]}]}