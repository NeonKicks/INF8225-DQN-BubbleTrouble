{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bubble_trouble_dqn.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"--4Tvqn6sI0B","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run this only once whenever the notebook is opened and no drive is mounted\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"toXxjgNdZ69y","colab_type":"code","colab":{}},"cell_type":"code","source":["# Run this if there is no gym-bubble-trouble repository\n","!cd drive/My\\ Drive/ && git clone https://github.com/ferasboulala/gym-bubble-trouble.git"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K1R_H3a1tEoS","colab_type":"code","colab":{}},"cell_type":"code","source":["# Updating the repository and reinstalling the module\n","!cd drive/My\\ Drive/gym-bubble-trouble && git pull origin master && pip install -e .\n","%cd drive/My\\ Drive/gym-bubble-trouble\n","\n","import sys\n","sys.path.append('bubbletrouble')\n","sys.path.append('gym_bubbletrouble/envs')\n","\n","!mkdir -p ../models"],"execution_count":0,"outputs":[]},{"metadata":{"colab_type":"code","outputId":"0509b773-edf9-4835-f3b5-0dd1023a72d8","executionInfo":{"status":"ok","timestamp":1555647799474,"user_tz":240,"elapsed":4973,"user":{"displayName":"Feras Boulala","photoUrl":"","userId":"14572603687652716755"}},"id":"Opp6-54drZbR","colab":{"base_uri":"https://localhost:8080/","height":316}},"cell_type":"code","source":["# OpenAI's gym\n","import gym\n","import gym.spaces\n","\n","# BubbleTrouble environment\n","import bubbletrouble_env\n","from bubbletrouble_env import BubbleTroubleEnv\n","\n","# std\n","import math\n","import random\n","import glob\n","\n","# 3rd party\n","import matplotlib.pyplot as plt\n","from collections import namedtuple\n","from itertools import count\n","from PIL import Image\n","import numpy as np\n","from IPython.display import clear_output\n","import cv2\n","\n","# pytorch\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","Transition = namedtuple('Transition',\n","                        ('state', 'action', 'next_state', 'reward'))\n","\n","class ReplayMemory(object):\n","    def __init__(self, capacity):\n","        self.capacity = capacity\n","        self.memory = []\n","        self.position = 0\n","\n","    def push(self, *args):\n","        if len(self.memory) < self.capacity:\n","            self.memory.append(None)\n","        self.memory[self.position] = Transition(*args)\n","        self.position = (self.position + 1) % self.capacity\n","\n","    def sample(self, batch_size):\n","        return random.sample(self.memory, batch_size)\n","\n","    def __len__(self):\n","        return len(self.memory)\n","\n","\n","class DQCNN(nn.Module):\n","    def __init__(self, h, w, outputs):\n","        super(DQCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n","        self.bn1 = nn.BatchNorm2d(16)\n","        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n","        self.bn2 = nn.BatchNorm2d(32)\n","        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n","        self.bn3 = nn.BatchNorm2d(32)\n","\n","        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n","            return (size - (kernel_size - 1) - 1) // stride  + 1\n","\n","        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n","        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n","        linear_input_size = convw * convh * 32\n","        self.fc = nn.Linear(linear_input_size, linear_input_size)\n","        self.head = nn.Linear(linear_input_size, outputs)\n","\n","    def forward(self, x):\n","        x = F.relu(self.bn1(self.conv1(x)))\n","        x = F.relu(self.bn2(self.conv2(x)))\n","        x = F.relu(self.bn3(self.conv3(x)))\n","        x = torch.relu(self.fc(x.view(x.size(0), -1)))\n","        return self.head(x)\n","    \n","      \n","class DQN(nn.Module):\n","    def __init__(self, n_inputs, n_outputs):\n","        super(DQN, self).__init__()\n","        self.fc1 = nn.Linear(n_inputs, 2*n_inputs)\n","        self.fc2 = nn.Linear(2*n_inputs, 2*n_inputs)\n","        self.fc3 = nn.Linear(2*n_inputs, 2*n_inputs)\n","        self.fc4 = nn.Linear(2*n_inputs, 2*n_inputs)\n","        self.fc5 = nn.Linear(2*n_inputs, 2*n_inputs)\n","        self.fc6 = nn.Linear(2*n_inputs, n_outputs)\n","        \n","    \n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        x = torch.relu(self.fc2(x))\n","        x = torch.relu(self.fc3(x))\n","        x = torch.relu(self.fc4(x))\n","        x = torch.relu(self.fc5(x))\n","        return self.fc6(x)\n","\n","\n","resize = T.Compose([T.ToPILImage(),\n","                    T.Resize(80, interpolation=Image.CUBIC),\n","                    T.ToTensor()])\n","\n","def get_screen():\n","    screen = env.render(mode='rgb_array')\n","    return resize(screen).unsqueeze(0).to(device)\n","\n","def convert_state(state):\n","    return torch.Tensor(state).unsqueeze(0).to(device)\n","  \n","    \n","# The following line does not work in colab\n","# env = gym.make('gym_bubbletrouble:BubbleTrouble-v0')\n","\n","reward_dict = {'moving': .0, 'fire': .0, 'score': 1.0, 'death': -1.0, 'win': .0, 'step': .0}\n","K = 5\n","training_cnn = True\n","\n","env = BubbleTroubleEnv(rewards=reward_dict, K=K, rand=True, timed=True)\n","env.reset()\n","plt.figure()\n","plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n","           interpolation='none')\n","plt.title('Bubble Trouble Screenshot')\n","plt.show()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["pygame 1.9.5\n","Hello from the pygame community. https://www.pygame.org/contribute.html\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAUUAAAEICAYAAADIsubvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"metadata":{"id":"uYpIa2PMI7OD","colab_type":"code","colab":{}},"cell_type":"code","source":["def compute_destroyed_balls(reward, steps):\n","    n = (reward - steps * reward_dict['step'] - \n","            reward_dict['death']) // reward_dict['score']\n","    if n < 0:\n","        return 0\n","    return int(n)\n","\n","        \n","def select_action(state, model, infer=False):\n","    global steps_done\n","    sample = random.random()\n","    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n","        math.exp(-1. * steps_done / EPS_DECAY)\n","    steps_done += 1\n","    if sample > eps_threshold or infer:\n","        with torch.no_grad():\n","            return model(state).max(1)[1].view(1, 1)\n","    else:\n","        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n","\n","\n","def optimize_model():\n","    if len(memory) < BATCH_SIZE:\n","        return 0\n","    transitions = memory.sample(BATCH_SIZE)\n","    batch = Transition(*zip(*transitions))\n","\n","    non_final_mask = None\n","    non_final_next_states = None\n","\n","    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n","                                          batch.next_state)), device=device, dtype=torch.uint8)\n","    non_final_next_states = torch.cat([s for s in batch.next_state\n","                                                if s is not None])\n","\n","    state_batch = torch.cat(batch.state)\n","    action_batch = torch.cat(batch.action)\n","    reward_batch = torch.cat(batch.reward)\n","\n","    state_action_values = policy_net(state_batch).gather(1, action_batch)\n","\n","    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n","    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n","    expected_state_action_values = (next_state_values * GAMMA) + reward_batch.type(torch.float)\n","\n","    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    for param in policy_net.parameters():\n","        param.grad.data.clamp_(-1, 1)\n","    optimizer.step()\n","    \n","    return loss.item()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"avIvT6WS1EZ2","colab_type":"code","colab":{}},"cell_type":"code","source":["BATCH_SIZE = 64\n","GAMMA = 0.99\n","EPS_START = 0.9\n","EPS_END = 0.05\n","EPS_DECAY = 50000\n","TARGET_UPDATE = 50\n","CHECKPOINT = TARGET_UPDATE\n","\n","MODEL_FN = '../models/bubble-trouble-dqn'\n","if training_cnn:\n","    MODEL_FN += '-cnn'\n","    \n","steps_done = 0\n","\n","init_screen = get_screen()\n","_, _, screen_height, screen_width = init_screen.shape\n","\n","n_actions = env.action_space.n\n","\n","policy_net = None\n","target_net = None\n","\n","if training_cnn:\n","    policy_net = DQCNN(screen_height, screen_width, n_actions).to(device)\n","    target_net = DQCNN(screen_height, screen_width, n_actions).to(device)\n","else:\n","    n_inputs = K * 5 + 4\n","    policy_net = DQN(n_inputs, n_actions).to(device)\n","    target_net = DQN(n_inputs, n_actions).to(device)\n","\n","target_net.load_state_dict(policy_net.state_dict())\n","target_net.eval()\n","\n","optimizer = optim.RMSprop(policy_net.parameters())\n","memory = ReplayMemory(50000)\n","\n","episode_durations = []\n","rewards = []"],"execution_count":0,"outputs":[]},{"metadata":{"id":"BXLfvZ0R8hu9","colab_type":"code","colab":{}},"cell_type":"code","source":["num_episodes = 10000\n","for i_episode in range(num_episodes):\n","    env.reset()\n","    \n","    state = None\n","    next_state = None\n","    last_state = None\n","    current_screen = None\n","    last_screen = None\n","    \n","    if training_cnn:\n","        # Black image\n","        last_screen = get_screen()\n","        current_screen = get_screen()\n","        state = current_screen - last_screen\n","    else:\n","        # Updating once with an idle action to get the first state\n","        state, _, _, _ = env.step(3)\n","        state = convert_state(state)\n","        last_state = state\n","        \n","    cum_reward = 0\n","    for t in count():\n","        action = select_action(state, policy_net)\n","        \n","        state, r, done, _ = env.step(action.item())\n","        state = convert_state(state)\n","        reward = torch.tensor([r], device=device)\n","        cum_reward += r\n","\n","        if training_cnn:\n","            state = current_screen - last_screen\n","            last_screen = current_screen\n","            current_screen = get_screen()\n","            \n","            if not done:\n","                next_state = current_screen - last_screen\n","            else:\n","                next_state = None\n","            memory.push(state, action, next_state, reward)\n","            state = next_state\n","        else:\n","            if done:\n","                state = None\n","            memory.push(last_state, action, state, reward)\n","            last_state = state\n","\n","        optimize_model()\n","        \n","        if done:\n","            episode_durations.append(t + 1)\n","            rewards.append(cum_reward)\n","            clear_output(wait=True)\n","            print(\n","                'Episode {}: Destroyed {} times in {} steps'\n","                .format(i_episode + 1, \n","                compute_destroyed_balls(cum_reward, t + 1), t + 1)\n","            )\n","            break\n","            \n","    if i_episode % TARGET_UPDATE == 0:\n","        target_net.load_state_dict(policy_net.state_dict())  \n","        \n","    if i_episode % CHECKPOINT == 0:\n","        torch.save({'model': policy_net.state_dict(), \n","                    'optimizer': optimizer.state_dict()}, MODEL_FN)\n","\n","print('Complete')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_qkY4_0ISqsj","colab_type":"code","colab":{}},"cell_type":"code","source":["def plot_durations():\n","    plt.figure()\n","    plt.clf()\n","    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n","    plt.title('')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Duration')\n","    plt.plot(durations_t.numpy())\n","    if len(durations_t) >= 100:\n","        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n","        means = torch.cat((torch.zeros(99), means))\n","        plt.plot(means.numpy())\n","        plt.legend(['Duration', 'Average'])\n","        \n","def plot_rewards():\n","    plt.figure()\n","    plt.clf()\n","    rewards_t = torch.tensor(rewards, dtype=torch.float)\n","    plt.title('')\n","    plt.xlabel('Episode')\n","    plt.ylabel('Reward')\n","    plt.plot(rewards_t.numpy()[10:])\n","    if len(rewards_t) >= 100:\n","        means = rewards_t.unfold(0, 100, 1).mean(1).view(-1)\n","        means = torch.cat((torch.zeros(99), means))\n","        plt.plot(means.numpy())\n","        plt.legend(['Reward', 'Average'])\n","\n","plot_durations()\n","plot_rewards()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"bNlO0g9NWRhm","colab_type":"code","colab":{}},"cell_type":"code","source":["model = None\n","if training_cnn:\n","    model = DQCNN(screen_height, screen_width, n_actions).to(device)\n","else:\n","    model = DQN(n_inputs, n_actions).to(device)\n","\n","checkpoint = torch.load(MODEL_FN)\n","model.load_state_dict(checkpoint['model'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.eval()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jCg8D13Qy_I8","colab_type":"code","colab":{}},"cell_type":"code","source":["env.reset()\n","\n","last_screen = get_screen()\n","current_screen = get_screen()\n","state = current_screen - last_screen\n","\n","if not training_cnn:\n","    state, _, _, _ = env.step(3)\n","    state = convert_state(state)\n","    \n","img_array = []\n","delta_array = []\n","cum_reward = 0\n","for i in range(bubbletrouble_env.MAX_N_STEPS):\n","    img_array.append(env.render_with_states()) # Taking the high res image.\n","    action = select_action(state, model=model, infer=True)\n","\n","    state, r, done, _ = env.step(action.item())\n","    state = convert_state(state)\n","    cum_reward += r\n","    \n","    last_screen = current_screen\n","    current_screen = get_screen()\n","\n","    if training_cnn:\n","        state = current_screen - last_screen\n","    if done:\n","        break\n","\n","print('Finished with {} reward and {} steps'.format(cum_reward, i))\n","      \n","# Call this only when you are sure you won't be using the model anymore.\n","# There is a pygame bug with fonts where if you quit, it will not restart.\n","### env.close()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GslGML6FqUSL","colab_type":"code","colab":{}},"cell_type":"code","source":["# Saving the playback\n","out = cv2.VideoWriter(\n","    '../models/dqn-result.mp4',\n","    cv2.VideoWriter_fourcc(*'DIVX'), \n","    30, \n","    (640, 480)\n",")\n","\n","for img in img_array:\n","    img_norm = cv2.cvtColor(np.uint8(img), cv2.COLOR_BGR2RGB)\n","    out.write(img_norm)\n","out.release()"],"execution_count":0,"outputs":[]}]}